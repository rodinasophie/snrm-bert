{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Automatic reload of local libraries\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "fqueries = '../ruwikIR/processed_queries.csv'\n",
    "fdocs = '../ruwikIR/processed_documents.csv'\n",
    "fqrels = '../ruwikIR/qrels'\n",
    "\n",
    "emb_file = '/home/mrim/data/embeddings/cc.ru.300.bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import fasttext\n",
    "\n",
    "model = fasttext.load_model(emb_file)\n",
    "\n",
    "def embedding_matrix(text, max_len):\n",
    "    words = text.split()\n",
    "    matrix = np.empty(())\n",
    "    dim = model.get_dimension()\n",
    "    matrix = np.zeros((max_len, dim))\n",
    "    for i in range(min(len(words), max_len)):\n",
    "        matrix[i] = model[words[i]]\n",
    "    return matrix\n",
    "\n",
    "def build_emb_input(batch):\n",
    "    output = []\n",
    "    for triple in batch:\n",
    "        q, d1, d2 = triple\n",
    "        q_m = embedding_matrix(q, max_len = 10)\n",
    "        d1_m = embedding_matrix(d1, max_len = 200)\n",
    "        d2_m = embedding_matrix(d2, max_len = 200)\n",
    "        output.append(np.array([q_m, d1_m, d2_m]))\n",
    "    return np.asarray(output)\n",
    "\n",
    "def reshape_4d(tensor):\n",
    "    return torch.from_numpy(tensor).float().view(1, tensor.shape[1], 1, tensor.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, layer_size, dropout_prob=0.6, ):\n",
    "        super().__init__()\n",
    "        self.layer_size = layer_size\n",
    "        self.fc = nn.ModuleList([])\n",
    "        for i in range(len(layer_size)-1):\n",
    "            self.fc.append(nn.Conv2d(layer_size[i], layer_size[i+1], (1, 5 if i == 0 else 1)))\n",
    "        self.dropout = nn.Dropout(p=dropout_prob, inplace=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i in range(len(self.fc)):\n",
    "            x = self.dropout(F.relu(self.fc[i](x)))\n",
    "        x=torch.mean(x, 3, keepdim=True)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO:\n",
    "2. Интегрировать tensorboardx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing data started...\n",
      "Finished.\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from utils import ModelInputGenerator\n",
    "\n",
    "mi_generator = ModelInputGenerator(fdocs, fqueries, fqrels)\n",
    "batch_num = 1\n",
    "autoencoder = Autoencoder([300, 100, 5000])\n",
    "criterion = nn.MarginRankingLoss(margin=1.0)\n",
    "optimizer = optim.SGD(autoencoder.parameters(), lr=0.001, momentum=0.9)\n",
    "reg_lambda = 10e-7 \n",
    "\n",
    "\n",
    "for epoch in range(1):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    mi_generator.reset()\n",
    "    for b in range(batch_num):\n",
    "        batch = mi_generator.generate_batch(size=4)\n",
    "        out_batch = build_emb_input(batch)\n",
    "        for i in range(out_batch.shape[0]):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            query, d1, d2 = out_batch[i]\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            # forward + backward + optimize\n",
    "\n",
    "            q_out = autoencoder(reshape_4d(query))\n",
    "            d1_out = autoencoder(reshape_4d(d1))\n",
    "            d2_out = autoencoder(reshape_4d(d2))\n",
    "            \n",
    "            reg_term = torch.cat((q_out, d1_out, d2_out), dim=1).sum(dim=1, keepdim=True)\n",
    "            x1 = (q_out * d1_out).sum(dim=1, keepdim=True)\n",
    "            x2 = (q_out * d2_out).sum(dim=1, keepdim=True)\n",
    "\n",
    "            target = torch.ones(1)\n",
    "            loss = criterion(x1, x2, target) + reg_lambda * reg_term\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 200 == 199:    # print every 2000 mini-batches\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / 2000))\n",
    "                running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zeros(x):\n",
    "    return len([i for i, e in enumerate(x) if e == 0])\n",
    "\n",
    "def get_zeros(x):\n",
    "    q, d1, d2 = x\n",
    "    qa = autoencoder(reshape_4d(q)).view(-1)\n",
    "    d1a = autoencoder(reshape_4d(d1)).view(-1)\n",
    "    d2a = autoencoder(reshape_4d(d2)).view(-1)\n",
    "    return zeros(qa), zeros(d1a), zeros(d2a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration #3:\n",
      "Zeros in query:  990\n",
      "Zeros in doc1:  796\n",
      "Zeros in doc2:  596\n",
      "Iteration #3:\n",
      "Zeros in query:  987\n",
      "Zeros in doc1:  817\n",
      "Zeros in doc2:  796\n",
      "Iteration #3:\n",
      "Zeros in query:  989\n",
      "Zeros in doc1:  819\n",
      "Zeros in doc2:  716\n",
      "Iteration #3:\n",
      "Zeros in query:  995\n",
      "Zeros in doc1:  823\n",
      "Zeros in doc2:  782\n",
      "Iteration #3:\n",
      "Zeros in query:  992\n",
      "Zeros in doc1:  792\n",
      "Zeros in doc2:  800\n",
      "Iteration #3:\n",
      "Zeros in query:  993\n",
      "Zeros in doc1:  800\n",
      "Zeros in doc2:  800\n",
      "Iteration #3:\n",
      "Zeros in query:  993\n",
      "Zeros in doc1:  791\n",
      "Zeros in doc2:  826\n",
      "Iteration #3:\n",
      "Zeros in query:  994\n",
      "Zeros in doc1:  824\n",
      "Zeros in doc2:  768\n",
      "Iteration #3:\n",
      "Zeros in query:  997\n",
      "Zeros in doc1:  792\n",
      "Zeros in doc2:  836\n",
      "Iteration #3:\n",
      "Zeros in query:  992\n",
      "Zeros in doc1:  795\n",
      "Zeros in doc2:  819\n",
      "Iteration #3:\n",
      "Zeros in query:  994\n",
      "Zeros in doc1:  806\n",
      "Zeros in doc2:  768\n",
      "Iteration #3:\n",
      "Zeros in query:  989\n",
      "Zeros in doc1:  807\n",
      "Zeros in doc2:  804\n",
      "Iteration #3:\n",
      "Zeros in query:  990\n",
      "Zeros in doc1:  830\n",
      "Zeros in doc2:  797\n",
      "Iteration #3:\n",
      "Zeros in query:  994\n",
      "Zeros in doc1:  800\n",
      "Zeros in doc2:  837\n",
      "Iteration #3:\n",
      "Zeros in query:  995\n",
      "Zeros in doc1:  795\n",
      "Zeros in doc2:  799\n",
      "Iteration #3:\n",
      "Zeros in query:  990\n",
      "Zeros in doc1:  732\n",
      "Zeros in doc2:  803\n",
      "Iteration #3:\n",
      "Zeros in query:  989\n",
      "Zeros in doc1:  782\n",
      "Zeros in doc2:  798\n",
      "Iteration #3:\n",
      "Zeros in query:  990\n",
      "Zeros in doc1:  745\n",
      "Zeros in doc2:  838\n",
      "Iteration #3:\n",
      "Zeros in query:  997\n",
      "Zeros in doc1:  848\n",
      "Zeros in doc2:  773\n",
      "Iteration #3:\n",
      "Zeros in query:  989\n",
      "Zeros in doc1:  858\n",
      "Zeros in doc2:  768\n"
     ]
    }
   ],
   "source": [
    "mi_generator.reset(4)\n",
    "batch = mi_generator.generate_batch(size=20)\n",
    "out_batch = build_emb_input(batch)\n",
    "    \n",
    "for x in out_batch:\n",
    "    q, d1, d2 = get_zeros(x)\n",
    "    print(\"Iteration #\"+str(i)+ \":\")\n",
    "    print(\"Zeros in query: \", q)\n",
    "    print(\"Zeros in doc1: \", d1)\n",
    "    print(\"Zeros in doc2: \", d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(autoencoder.state_dict(), './autoencoder.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
