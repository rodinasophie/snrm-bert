{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatic reload of local libraries\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "fqueries = '../ruwikIR/processed_queries.csv'\n",
    "fdocs = '../ruwikIR/processed_documents.csv'\n",
    "fqrels = '../ruwikIR/qrels'\n",
    "\n",
    "emb_file = '/home/mrim/data/embeddings/cc.ru.300.bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import fasttext\n",
    "\n",
    "model = fasttext.load_model(emb_file)\n",
    "\n",
    "def embedding_matrix(text, max_len):\n",
    "    words = text.split()\n",
    "    matrix = np.empty(())\n",
    "    dim = model.get_dimension()\n",
    "    matrix = np.zeros((max_len, dim))\n",
    "    for i in range(min(len(words), max_len)):\n",
    "        matrix[i] = model[words[i]]\n",
    "    return matrix\n",
    "\n",
    "def build_emb_input(batch):\n",
    "    output = []\n",
    "    for triple in batch:\n",
    "        q, d1, d2 = triple\n",
    "        q_m = embedding_matrix(q, max_len = 10)\n",
    "        d1_m = embedding_matrix(d1, max_len = 200)\n",
    "        d2_m = embedding_matrix(d2, max_len = 200)\n",
    "        output.append(np.array([q_m, d1_m, d2_m]))\n",
    "    return np.asarray(output)\n",
    "\n",
    "def reshape_4d(tensor):\n",
    "    return torch.from_numpy(tensor).float().view(1, tensor.shape[1], 1, tensor.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, layer_size, dropout_prob=0.6):\n",
    "        super().__init__()\n",
    "        self.layer_size = layer_size\n",
    "        self.fc = nn.ModuleList([])\n",
    "        for i in range(len(layer_size)-1):\n",
    "            self.fc.append(nn.Conv2d(layer_size[i], layer_size[i+1], (1, 5 if i == 0 else 1)))\n",
    "        self.dropout = nn.Dropout(p=dropout_prob, inplace=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i in range(len(self.fc)):\n",
    "            x = self.dropout(F.relu(self.fc[i](x)))\n",
    "        x=torch.mean(x, 3, keepdim=True)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO:\n",
    "2. Интегрировать tensorboardx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing data started...\n",
      "Finished.\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from utils import ModelInputGenerator\n",
    "\n",
    "mi_generator = ModelInputGenerator(fdocs, fqueries, fqrels)\n",
    "batch_num = 1\n",
    "autoencoder = Autoencoder([300, 100, 5000])\n",
    "criterion = nn.MarginRankingLoss(margin=1.0)\n",
    "optimizer = optim.SGD(autoencoder.parameters(), lr=0.001, momentum=0.9)\n",
    "reg_lambda = 10e-7 \n",
    "\n",
    "\n",
    "for epoch in range(1):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    mi_generator.reset()\n",
    "    for b in range(batch_num):\n",
    "        batch = mi_generator.generate_batch(size=4)\n",
    "        out_batch = build_emb_input(batch)\n",
    "        for i in range(out_batch.shape[0]):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            query, d1, d2 = out_batch[i]\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            # forward + backward + optimize\n",
    "\n",
    "            q_out = autoencoder(reshape_4d(query))\n",
    "            d1_out = autoencoder(reshape_4d(d1))\n",
    "            d2_out = autoencoder(reshape_4d(d2))\n",
    "            \n",
    "            reg_term = torch.cat((q_out, d1_out, d2_out), dim=1).sum(dim=1, keepdim=True)\n",
    "            x1 = (q_out * d1_out).sum(dim=1, keepdim=True)\n",
    "            x2 = (q_out * d2_out).sum(dim=1, keepdim=True)\n",
    "\n",
    "            target = torch.ones(1)\n",
    "            loss = criterion(x1, x2, target) + reg_lambda * reg_term\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 200 == 199:    # print every 2000 mini-batches\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / 2000))\n",
    "                running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zeros(x):\n",
    "    return len([i for i, e in enumerate(x) if e == 0])\n",
    "\n",
    "def get_zeros(x):\n",
    "    q, d1, d2 = x\n",
    "    qa = autoencoder(reshape_4d(q)).view(-1)\n",
    "    d1a = autoencoder(reshape_4d(d1)).view(-1)\n",
    "    d2a = autoencoder(reshape_4d(d2)).view(-1)\n",
    "    return zeros(qa), zeros(d1a), zeros(d2a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration #3:\n",
      "Zeros in query:  990\n",
      "Zeros in doc1:  796\n",
      "Zeros in doc2:  596\n",
      "Iteration #3:\n",
      "Zeros in query:  987\n",
      "Zeros in doc1:  817\n",
      "Zeros in doc2:  796\n",
      "Iteration #3:\n",
      "Zeros in query:  989\n",
      "Zeros in doc1:  819\n",
      "Zeros in doc2:  716\n",
      "Iteration #3:\n",
      "Zeros in query:  995\n",
      "Zeros in doc1:  823\n",
      "Zeros in doc2:  782\n",
      "Iteration #3:\n",
      "Zeros in query:  992\n",
      "Zeros in doc1:  792\n",
      "Zeros in doc2:  800\n",
      "Iteration #3:\n",
      "Zeros in query:  993\n",
      "Zeros in doc1:  800\n",
      "Zeros in doc2:  800\n",
      "Iteration #3:\n",
      "Zeros in query:  993\n",
      "Zeros in doc1:  791\n",
      "Zeros in doc2:  826\n",
      "Iteration #3:\n",
      "Zeros in query:  994\n",
      "Zeros in doc1:  824\n",
      "Zeros in doc2:  768\n",
      "Iteration #3:\n",
      "Zeros in query:  997\n",
      "Zeros in doc1:  792\n",
      "Zeros in doc2:  836\n",
      "Iteration #3:\n",
      "Zeros in query:  992\n",
      "Zeros in doc1:  795\n",
      "Zeros in doc2:  819\n",
      "Iteration #3:\n",
      "Zeros in query:  994\n",
      "Zeros in doc1:  806\n",
      "Zeros in doc2:  768\n",
      "Iteration #3:\n",
      "Zeros in query:  989\n",
      "Zeros in doc1:  807\n",
      "Zeros in doc2:  804\n",
      "Iteration #3:\n",
      "Zeros in query:  990\n",
      "Zeros in doc1:  830\n",
      "Zeros in doc2:  797\n",
      "Iteration #3:\n",
      "Zeros in query:  994\n",
      "Zeros in doc1:  800\n",
      "Zeros in doc2:  837\n",
      "Iteration #3:\n",
      "Zeros in query:  995\n",
      "Zeros in doc1:  795\n",
      "Zeros in doc2:  799\n",
      "Iteration #3:\n",
      "Zeros in query:  990\n",
      "Zeros in doc1:  732\n",
      "Zeros in doc2:  803\n",
      "Iteration #3:\n",
      "Zeros in query:  989\n",
      "Zeros in doc1:  782\n",
      "Zeros in doc2:  798\n",
      "Iteration #3:\n",
      "Zeros in query:  990\n",
      "Zeros in doc1:  745\n",
      "Zeros in doc2:  838\n",
      "Iteration #3:\n",
      "Zeros in query:  997\n",
      "Zeros in doc1:  848\n",
      "Zeros in doc2:  773\n",
      "Iteration #3:\n",
      "Zeros in query:  989\n",
      "Zeros in doc1:  858\n",
      "Zeros in doc2:  768\n"
     ]
    }
   ],
   "source": [
    "mi_generator.reset(4)\n",
    "batch = mi_generator.generate_batch(size=20)\n",
    "out_batch = build_emb_input(batch)\n",
    "    \n",
    "for x in out_batch:\n",
    "    q, d1, d2 = get_zeros(x)\n",
    "    print(\"Iteration #\"+str(i)+ \":\")\n",
    "    print(\"Zeros in query: \", q)\n",
    "    print(\"Zeros in doc1: \", d1)\n",
    "    print(\"Zeros in doc2: \", d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(autoencoder.state_dict(), './autoencoder.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModuleSpec(name='config', loader=<_frozen_importlib_external.SourceFileLoader object at 0x000001A6FA7C6588>, origin='./model/params.py')\n",
      "<class 'module'>\n"
     ]
    }
   ],
   "source": [
    "import importlib.util\n",
    "import argparse\n",
    "import datetime\n",
    "import distutils.util\n",
    "import importlib.util\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import shutil\n",
    "\n",
    "spec = importlib.util.spec_from_file_location(\"config\", './model/params.py')\n",
    "print(spec)\n",
    "cmodule = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(cmodule)\n",
    "print(type(cmodule))\n",
    "configs = cmodule.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./model/params.json') as f:\n",
    "    params = json.load(f)\n",
    "type(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docs ../ruwikIR/processed_documents.csv\n",
      "queries ../ruwikIR/processed_queries.csv\n",
      "qrels ../ruwikIR/qrels\n",
      "embeddings /home/mrim/data/embeddings/cc.ru.300.bin\n",
      "inverted_index ./inverted_index.csv\n",
      "outmodel ./model.pth\n",
      "learning_rate {'value': 5, 'power': 0.0001}\n",
      "epoches 2\n",
      "batch_size 32\n",
      "layers [300, 200, 5000]\n",
      "lambda {'value': 1, 'power': 1e-06}\n",
      "drop_prob 0.6\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for key, val in params.items():\n",
    "    print(key, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snrm import InvertedIndexConstructor\n",
    "import torch\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5257, 0.3658, 0.4391, 0.0659, 0.3592, 0.3121, 0.7426, 0.1992, 0.0000,\n",
      "        0.5123, 0.3275, 0.0671, 0.9164, 0.8634, 0.9826, 0.2818, 0.8634, 0.0939,\n",
      "        0.7273, 0.0815])\n"
     ]
    }
   ],
   "source": [
    "index_constr = InvertedIndexConstructor(\"./file.txt\")\n",
    "repr_tensor = torch.rand(5, 20)\n",
    "for i in range(5):\n",
    "    r = random.randint(0, 20)\n",
    "    repr_tensor[i][r] = 0.0\n",
    "    \n",
    "print(repr_tensor[0]) \n",
    "index_constr.construct(range(5), repr_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [(0, tensor(0.5257)),\n",
       "  (1, tensor(0.1797)),\n",
       "  (2, tensor(0.8578)),\n",
       "  (3, tensor(0.5252)),\n",
       "  (4, tensor(0.2159))],\n",
       " 1: [(0, tensor(0.3658)),\n",
       "  (1, tensor(0.3023)),\n",
       "  (2, tensor(0.9728)),\n",
       "  (3, tensor(0.8307)),\n",
       "  (4, tensor(0.6781))],\n",
       " 2: [(0, tensor(0.4391)),\n",
       "  (1, tensor(0.0421)),\n",
       "  (2, tensor(0.3877)),\n",
       "  (3, tensor(0.3592))],\n",
       " 3: [(0, tensor(0.0659)),\n",
       "  (1, tensor(0.3625)),\n",
       "  (3, tensor(0.6913)),\n",
       "  (4, tensor(0.3166))],\n",
       " 4: [(0, tensor(0.3592)),\n",
       "  (2, tensor(0.6451)),\n",
       "  (3, tensor(0.5580)),\n",
       "  (4, tensor(0.5135))],\n",
       " 5: [(0, tensor(0.3121)),\n",
       "  (1, tensor(0.6315)),\n",
       "  (2, tensor(0.9155)),\n",
       "  (3, tensor(0.5570)),\n",
       "  (4, tensor(0.2516))],\n",
       " 6: [(0, tensor(0.7426)),\n",
       "  (1, tensor(0.8405)),\n",
       "  (2, tensor(0.3915)),\n",
       "  (4, tensor(0.7029))],\n",
       " 7: [(0, tensor(0.1992)),\n",
       "  (1, tensor(0.4625)),\n",
       "  (2, tensor(0.8267)),\n",
       "  (3, tensor(0.1101)),\n",
       "  (4, tensor(0.1669))],\n",
       " 9: [(0, tensor(0.5123)),\n",
       "  (1, tensor(0.2745)),\n",
       "  (2, tensor(0.2430)),\n",
       "  (3, tensor(0.2082)),\n",
       "  (4, tensor(0.5402))],\n",
       " 10: [(0, tensor(0.3275)),\n",
       "  (1, tensor(0.1291)),\n",
       "  (2, tensor(0.2545)),\n",
       "  (3, tensor(0.9263)),\n",
       "  (4, tensor(0.7899))],\n",
       " 11: [(0, tensor(0.0671)),\n",
       "  (1, tensor(0.4902)),\n",
       "  (2, tensor(0.1905)),\n",
       "  (3, tensor(0.3409)),\n",
       "  (4, tensor(0.2316))],\n",
       " 12: [(0, tensor(0.9164)),\n",
       "  (1, tensor(0.0314)),\n",
       "  (2, tensor(0.4420)),\n",
       "  (3, tensor(0.1578)),\n",
       "  (4, tensor(0.1601))],\n",
       " 13: [(0, tensor(0.8634)),\n",
       "  (1, tensor(0.6427)),\n",
       "  (2, tensor(0.6695)),\n",
       "  (3, tensor(0.4785)),\n",
       "  (4, tensor(0.0482))],\n",
       " 14: [(0, tensor(0.9826)),\n",
       "  (1, tensor(0.2017)),\n",
       "  (2, tensor(0.5154)),\n",
       "  (3, tensor(0.2587)),\n",
       "  (4, tensor(0.9093))],\n",
       " 15: [(0, tensor(0.2818)),\n",
       "  (1, tensor(0.3392)),\n",
       "  (2, tensor(0.2083)),\n",
       "  (3, tensor(0.5883)),\n",
       "  (4, tensor(0.0093))],\n",
       " 16: [(0, tensor(0.8634)),\n",
       "  (1, tensor(0.8892)),\n",
       "  (2, tensor(0.3941)),\n",
       "  (3, tensor(0.6540)),\n",
       "  (4, tensor(0.5371))],\n",
       " 17: [(0, tensor(0.0939)),\n",
       "  (1, tensor(0.3115)),\n",
       "  (2, tensor(0.6863)),\n",
       "  (3, tensor(0.4182)),\n",
       "  (4, tensor(0.4791))],\n",
       " 18: [(0, tensor(0.7273)),\n",
       "  (1, tensor(0.6975)),\n",
       "  (2, tensor(0.2248)),\n",
       "  (3, tensor(0.2945)),\n",
       "  (4, tensor(0.2661))],\n",
       " 19: [(0, tensor(0.0815)),\n",
       "  (1, tensor(0.4893)),\n",
       "  (2, tensor(0.5222)),\n",
       "  (3, tensor(0.4968)),\n",
       "  (4, tensor(0.7898))],\n",
       " 8: [(1, tensor(0.4850)),\n",
       "  (2, tensor(0.6951)),\n",
       "  (3, tensor(0.4831)),\n",
       "  (4, tensor(0.8045))]}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_constr.get_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
