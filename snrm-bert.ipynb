{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Automatic reload of local libraries\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "fqueries = '../ruwikIR/processed_queries.csv'\n",
    "fdocs = '../ruwikIR/processed_documents.csv'\n",
    "fqrels = '../ruwikIR/qrels'\n",
    "\n",
    "emb_file = '/home/mrim/data/embeddings/cc.ru.300.bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import fasttext\n",
    "\n",
    "model = fasttext.load_model(emb_file)\n",
    "\n",
    "def embedding_matrix(text, max_len):\n",
    "    words = text.split()\n",
    "    matrix = np.empty(())\n",
    "    dim = model.get_dimension()\n",
    "    matrix = np.zeros((max_len, dim))\n",
    "    for i in range(min(len(words), max_len)):\n",
    "        matrix[i] = model[words[i]]\n",
    "    return matrix\n",
    "\n",
    "def build_emb_input(batch):\n",
    "    output = []\n",
    "    for triple in batch:\n",
    "        q, d1, d2 = triple\n",
    "        q_m = embedding_matrix(q, max_len = 10)\n",
    "        d1_m = embedding_matrix(d1, max_len = 200)\n",
    "        d2_m = embedding_matrix(d2, max_len = 200)\n",
    "        output.append(np.array([q_m, d1_m, d2_m]))\n",
    "    return np.asarray(output)\n",
    "\n",
    "def reshape_4d(tensor):\n",
    "    return torch.from_numpy(tensor).float().view(1, tensor.shape[1], 1, tensor.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, layer_size, dropout_prob=0.6):\n",
    "        super().__init__()\n",
    "        self.layer_size = layer_size\n",
    "        self.fc = nn.ModuleList([])\n",
    "        for i in range(len(layer_size)-1):\n",
    "            self.fc.append(nn.Conv2d(layer_size[i], layer_size[i+1], (1, 5 if i == 0 else 1)))\n",
    "        self.dropout = nn.Dropout(p=dropout_prob, inplace=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i in range(len(self.fc)):\n",
    "            x = self.dropout(F.relu(self.fc[i](x)))\n",
    "        x=torch.mean(x, 3, keepdim=True)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO:\n",
    "2. Интегрировать tensorboardx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing data started...\n",
      "Finished.\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from utils import ModelInputGenerator\n",
    "\n",
    "mi_generator = ModelInputGenerator(fdocs, fqueries, fqrels)\n",
    "batch_num = 1\n",
    "autoencoder = Autoencoder([300, 100, 5000])\n",
    "criterion = nn.MarginRankingLoss(margin=1.0)\n",
    "optimizer = optim.SGD(autoencoder.parameters(), lr=0.001, momentum=0.9)\n",
    "reg_lambda = 10e-7 \n",
    "\n",
    "\n",
    "for epoch in range(1):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    mi_generator.reset()\n",
    "    for b in range(batch_num):\n",
    "        batch = mi_generator.generate_batch(size=4)\n",
    "        out_batch = build_emb_input(batch)\n",
    "        for i in range(out_batch.shape[0]):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            query, d1, d2 = out_batch[i]\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            # forward + backward + optimize\n",
    "\n",
    "            q_out = autoencoder(reshape_4d(query))\n",
    "            d1_out = autoencoder(reshape_4d(d1))\n",
    "            d2_out = autoencoder(reshape_4d(d2))\n",
    "            \n",
    "            reg_term = torch.cat((q_out, d1_out, d2_out), dim=1).sum(dim=1, keepdim=True)\n",
    "            x1 = (q_out * d1_out).sum(dim=1, keepdim=True)\n",
    "            x2 = (q_out * d2_out).sum(dim=1, keepdim=True)\n",
    "\n",
    "            target = torch.ones(1)\n",
    "            loss = criterion(x1, x2, target) + reg_lambda * reg_term\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 200 == 199:    # print every 2000 mini-batches\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / 2\n",
    "                       000))\n",
    "                running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zeros(x):\n",
    "    return len([i for i, e in enumerate(x) if e == 0])\n",
    "\n",
    "def get_zeros(x):\n",
    "    q, d1, d2 = x\n",
    "    qa = autoencoder(reshape_4d(q)).view(-1)\n",
    "    d1a = autoencoder(reshape_4d(d1)).view(-1)\n",
    "    d2a = autoencoder(reshape_4d(d2)).view(-1)\n",
    "    return zeros(qa), zeros(d1a), zeros(d2a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration #3:\n",
      "Zeros in query:  990\n",
      "Zeros in doc1:  796\n",
      "Zeros in doc2:  596\n",
      "Iteration #3:\n",
      "Zeros in query:  987\n",
      "Zeros in doc1:  817\n",
      "Zeros in doc2:  796\n",
      "Iteration #3:\n",
      "Zeros in query:  989\n",
      "Zeros in doc1:  819\n",
      "Zeros in doc2:  716\n",
      "Iteration #3:\n",
      "Zeros in query:  995\n",
      "Zeros in doc1:  823\n",
      "Zeros in doc2:  782\n",
      "Iteration #3:\n",
      "Zeros in query:  992\n",
      "Zeros in doc1:  792\n",
      "Zeros in doc2:  800\n",
      "Iteration #3:\n",
      "Zeros in query:  993\n",
      "Zeros in doc1:  800\n",
      "Zeros in doc2:  800\n",
      "Iteration #3:\n",
      "Zeros in query:  993\n",
      "Zeros in doc1:  791\n",
      "Zeros in doc2:  826\n",
      "Iteration #3:\n",
      "Zeros in query:  994\n",
      "Zeros in doc1:  824\n",
      "Zeros in doc2:  768\n",
      "Iteration #3:\n",
      "Zeros in query:  997\n",
      "Zeros in doc1:  792\n",
      "Zeros in doc2:  836\n",
      "Iteration #3:\n",
      "Zeros in query:  992\n",
      "Zeros in doc1:  795\n",
      "Zeros in doc2:  819\n",
      "Iteration #3:\n",
      "Zeros in query:  994\n",
      "Zeros in doc1:  806\n",
      "Zeros in doc2:  768\n",
      "Iteration #3:\n",
      "Zeros in query:  989\n",
      "Zeros in doc1:  807\n",
      "Zeros in doc2:  804\n",
      "Iteration #3:\n",
      "Zeros in query:  990\n",
      "Zeros in doc1:  830\n",
      "Zeros in doc2:  797\n",
      "Iteration #3:\n",
      "Zeros in query:  994\n",
      "Zeros in doc1:  800\n",
      "Zeros in doc2:  837\n",
      "Iteration #3:\n",
      "Zeros in query:  995\n",
      "Zeros in doc1:  795\n",
      "Zeros in doc2:  799\n",
      "Iteration #3:\n",
      "Zeros in query:  990\n",
      "Zeros in doc1:  732\n",
      "Zeros in doc2:  803\n",
      "Iteration #3:\n",
      "Zeros in query:  989\n",
      "Zeros in doc1:  782\n",
      "Zeros in doc2:  798\n",
      "Iteration #3:\n",
      "Zeros in query:  990\n",
      "Zeros in doc1:  745\n",
      "Zeros in doc2:  838\n",
      "Iteration #3:\n",
      "Zeros in query:  997\n",
      "Zeros in doc1:  848\n",
      "Zeros in doc2:  773\n",
      "Iteration #3:\n",
      "Zeros in query:  989\n",
      "Zeros in doc1:  858\n",
      "Zeros in doc2:  768\n"
     ]
    }
   ],
   "source": [
    "mi_generator.reset(4)\n",
    "batch = mi_generator.generate_batch(size=20)\n",
    "out_batch = build_emb_input(batch)\n",
    "    \n",
    "for x in out_batch:\n",
    "    q, d1, d2 = get_zeros(x)\n",
    "    print(\"Iteration #\"+str(i)+ \":\")\n",
    "    print(\"Zeros in query: \", q)\n",
    "    print(\"Zeros in doc1: \", d1)\n",
    "    print(\"Zeros in doc2: \", d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(autoencoder.state_dict(), './autoencoder.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModuleSpec(name='config', loader=<_frozen_importlib_external.SourceFileLoader object at 0x000001A6FA7C6588>, origin='./model/params.py')\n",
      "<class 'module'>\n"
     ]
    }
   ],
   "source": [
    "import importlib.util\n",
    "import argparse\n",
    "import datetime\n",
    "import distutils.util\n",
    "import importlib.util\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import shutil\n",
    "\n",
    "spec = importlib.util.spec_from_file_location(\"config\", './model/params.py')\n",
    "print(spec)\n",
    "cmodule = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(cmodule)\n",
    "print(type(cmodule))\n",
    "configs = cmodule.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./model/params.json') as f:\n",
    "    params = json.load(f)\n",
    "type(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docs ../ruwikIR/processed_documents.csv\n",
      "queries ../ruwikIR/processed_queries.csv\n",
      "qrels ../ruwikIR/qrels\n",
      "embeddings /home/mrim/data/embeddings/cc.ru.300.bin\n",
      "inverted_index ./inverted_index.csv\n",
      "outmodel ./model.pth\n",
      "learning_rate {'value': 5, 'power': 0.0001}\n",
      "epoches 2\n",
      "batch_size 32\n",
      "layers [300, 200, 5000]\n",
      "lambda {'value': 1, 'power': 1e-06}\n",
      "drop_prob 0.6\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for key, val in params.items():\n",
    "    print(key, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snrm import InvertedIndex\n",
    "import torch\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6626, 0.7634, 0.3152, 0.9138, 0.0000, 0.9281, 0.1381, 0.1911, 0.8263,\n",
      "        0.9297, 0.5980, 0.0308, 0.8186, 0.0843, 0.0141, 0.3353, 0.2179, 0.2511,\n",
      "        0.4956, 0.3442])\n"
     ]
    }
   ],
   "source": [
    "index_constr = InvertedIndex(\"./file.txt\")\n",
    "repr_tensor = torch.rand(5, 20)\n",
    "for i in range(5):\n",
    "    r = random.randint(0, 19)\n",
    "    repr_tensor[i][r] = 0.0\n",
    "    \n",
    "print(repr_tensor[0]) \n",
    "index_constr.construct(range(5), repr_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_constr.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': [[0, 0.6625607013702393],\n",
       "  [1, 0.8118937611579895],\n",
       "  [2, 0.17625075578689575],\n",
       "  [3, 0.8161836862564087],\n",
       "  [4, 0.22455036640167236]],\n",
       " '1': [[0, 0.7633713483810425],\n",
       "  [1, 0.602530837059021],\n",
       "  [2, 0.48982852697372437],\n",
       "  [3, 0.5182974934577942],\n",
       "  [4, 0.49064409732818604]],\n",
       " '2': [[0, 0.3151988387107849],\n",
       "  [1, 0.9322848320007324],\n",
       "  [2, 0.8350390791893005],\n",
       "  [3, 0.9327800869941711],\n",
       "  [4, 0.5328416228294373]],\n",
       " '3': [[0, 0.9137703776359558],\n",
       "  [2, 0.32753509283065796],\n",
       "  [3, 0.5071824193000793],\n",
       "  [4, 0.06532859802246094]],\n",
       " '5': [[0, 0.9281238913536072],\n",
       "  [1, 0.457541823387146],\n",
       "  [2, 0.11879563331604004],\n",
       "  [3, 0.9908499717712402],\n",
       "  [4, 0.7916132807731628]],\n",
       " '6': [[0, 0.1381348967552185],\n",
       "  [1, 0.9111696481704712],\n",
       "  [2, 0.9475979804992676],\n",
       "  [3, 0.02024853229522705],\n",
       "  [4, 0.04052388668060303]],\n",
       " '7': [[0, 0.19107496738433838],\n",
       "  [1, 0.012347698211669922],\n",
       "  [2, 0.6920667886734009],\n",
       "  [3, 0.0009909272193908691],\n",
       "  [4, 0.5567017793655396]],\n",
       " '8': [[0, 0.8262988328933716],\n",
       "  [1, 0.8385286331176758],\n",
       "  [2, 0.8032329678535461],\n",
       "  [3, 0.1496078372001648],\n",
       "  [4, 0.2034306526184082]],\n",
       " '9': [[0, 0.9297404289245605],\n",
       "  [1, 0.027682185173034668],\n",
       "  [2, 0.793115496635437],\n",
       "  [3, 0.9480485916137695],\n",
       "  [4, 0.01627880334854126]],\n",
       " '10': [[0, 0.5979781150817871],\n",
       "  [1, 0.6768271327018738],\n",
       "  [2, 0.6010857820510864],\n",
       "  [3, 0.9522432684898376]],\n",
       " '11': [[0, 0.030834853649139404],\n",
       "  [1, 0.35816287994384766],\n",
       "  [2, 0.6721649169921875],\n",
       "  [4, 0.5205318331718445]],\n",
       " '12': [[0, 0.818638265132904],\n",
       "  [1, 0.5002419352531433],\n",
       "  [2, 0.7005904316902161],\n",
       "  [3, 0.883933961391449],\n",
       "  [4, 0.5200607776641846]],\n",
       " '13': [[0, 0.08434814214706421],\n",
       "  [1, 0.45921558141708374],\n",
       "  [3, 0.34285593032836914],\n",
       "  [4, 0.8457197546958923]],\n",
       " '14': [[0, 0.014077603816986084],\n",
       "  [1, 0.5674281716346741],\n",
       "  [2, 0.40850305557250977],\n",
       "  [3, 0.936720609664917],\n",
       "  [4, 0.6621972918510437]],\n",
       " '15': [[0, 0.3353252410888672],\n",
       "  [1, 0.29402148723602295],\n",
       "  [2, 0.13448834419250488],\n",
       "  [3, 0.0817795991897583],\n",
       "  [4, 0.04799407720565796]],\n",
       " '16': [[0, 0.21790510416030884],\n",
       "  [1, 0.9624054431915283],\n",
       "  [2, 0.9627258777618408],\n",
       "  [3, 0.45378202199935913],\n",
       "  [4, 0.5362828969955444]],\n",
       " '17': [[0, 0.25107860565185547],\n",
       "  [1, 0.9016177654266357],\n",
       "  [2, 0.40328818559646606],\n",
       "  [3, 0.36525046825408936],\n",
       "  [4, 0.5663507580757141]],\n",
       " '18': [[0, 0.495633065700531],\n",
       "  [1, 0.7777905464172363],\n",
       "  [2, 0.7372738122940063],\n",
       "  [3, 0.9267634749412537],\n",
       "  [4, 0.5801119208335876]],\n",
       " '19': [[0, 0.34419918060302734],\n",
       "  [1, 0.08554345369338989],\n",
       "  [2, 0.9013491272926331],\n",
       "  [3, 0.2727099657058716],\n",
       "  [4, 0.9879521131515503]],\n",
       " '4': [[1, 0.2924405336380005],\n",
       "  [2, 0.8612502813339233],\n",
       "  [3, 0.7691752910614014],\n",
       "  [4, 0.7782449126243591]]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_constr.read_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to mnist_train\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████▉| 9904128/9912422 [01:33<00:00, 113001.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist_train\\MNIST\\raw\\train-images-idx3-ubyte.gz to mnist_train\\MNIST\\raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to mnist_train\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                        | 0/28881 [00:00<?, ?it/s]\u001b[A\n",
      "32768it [00:01, 32292.11it/s]                                                                                          \u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist_train\\MNIST\\raw\\train-labels-idx1-ubyte.gz to mnist_train\\MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to mnist_train\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                      | 0/1648877 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|█                                                                     | 24576/1648877 [00:00<00:10, 157724.90it/s]\u001b[A\n",
      "  2%|█▋                                                                    | 40960/1648877 [00:00<00:11, 137429.31it/s]\u001b[A\n",
      "  3%|██                                                                    | 49152/1648877 [00:00<00:15, 103515.39it/s]\u001b[A\n",
      "  4%|███▏                                                                  | 73728/1648877 [00:01<00:14, 106598.00it/s]\u001b[A\n",
      "  5%|███▌                                                                   | 81920/1648877 [00:01<00:21, 72422.51it/s]\u001b[A\n",
      "  5%|███▉                                                                   | 90112/1648877 [00:01<00:38, 40804.16it/s]\u001b[A\n",
      " 10%|███████▎                                                              | 172032/1648877 [00:02<00:28, 51421.14it/s]\u001b[A\n",
      " 12%|████████▎                                                             | 196608/1648877 [00:02<00:22, 64127.69it/s]\u001b[A\n",
      " 13%|█████████                                                             | 212992/1648877 [00:02<00:18, 75850.32it/s]\u001b[A\n",
      " 14%|█████████▋                                                            | 229376/1648877 [00:02<00:17, 80613.78it/s]\u001b[A\n",
      " 15%|██████████▍                                                           | 245760/1648877 [00:03<00:18, 74776.33it/s]\u001b[A\n",
      " 16%|███████████▏                                                          | 262144/1648877 [00:03<00:25, 54137.35it/s]\u001b[A\n",
      " 16%|███████████▍                                                          | 270336/1648877 [00:03<00:26, 52119.00it/s]\u001b[A\n",
      " 17%|████████████▏                                                         | 286720/1648877 [00:04<00:25, 53898.70it/s]\u001b[A\n",
      " 19%|█████████████▌                                                        | 319488/1648877 [00:04<00:18, 71826.21it/s]\u001b[A\n",
      " 20%|██████████████▎                                                       | 335872/1648877 [00:04<00:18, 72541.23it/s]\u001b[A\n",
      " 21%|██████████████▉                                                       | 352256/1648877 [00:04<00:17, 74244.01it/s]\u001b[A\n",
      " 22%|███████████████▋                                                      | 368640/1648877 [00:04<00:17, 73677.70it/s]\u001b[A\n",
      " 23%|████████████████▎                                                     | 385024/1648877 [00:04<00:15, 82104.04it/s]\u001b[A\n",
      " 24%|█████████████████                                                     | 401408/1648877 [00:05<00:14, 86386.18it/s]\u001b[A\n",
      " 25%|█████████████████▋                                                    | 417792/1648877 [00:05<00:13, 91611.72it/s]\u001b[A\n",
      " 26%|██████████████████▏                                                  | 434176/1648877 [00:05<00:11, 103915.55it/s]\u001b[A\n",
      " 27%|███████████████████▏                                                  | 450560/1648877 [00:05<00:12, 96646.15it/s]\u001b[A\n",
      " 28%|███████████████████▊                                                  | 466944/1648877 [00:05<00:12, 92422.69it/s]\u001b[A\n",
      " 29%|████████████████████▌                                                 | 483328/1648877 [00:06<00:15, 73038.88it/s]\u001b[A\n",
      " 30%|█████████████████████▏                                                | 499712/1648877 [00:06<00:14, 81316.71it/s]\u001b[A\n",
      " 31%|█████████████████████▉                                                | 516096/1648877 [00:06<00:14, 76092.52it/s]\u001b[A\n",
      " 32%|██████████████████████▌                                               | 532480/1648877 [00:06<00:14, 78205.97it/s]\u001b[A\n",
      " 33%|███████████████████████▎                                              | 548864/1648877 [00:06<00:13, 79534.09it/s]\u001b[A\n",
      " 34%|███████████████████████▉                                              | 565248/1648877 [00:07<00:12, 89601.33it/s]\u001b[A\n",
      " 35%|████████████████████████▋                                             | 581632/1648877 [00:07<00:12, 82660.06it/s]\u001b[A\n",
      " 36%|█████████████████████████▍                                            | 598016/1648877 [00:07<00:13, 77611.75it/s]\u001b[A\n",
      " 38%|██████████████████████████▍                                           | 622592/1648877 [00:07<00:11, 91909.10it/s]\u001b[A\n",
      " 39%|███████████████████████████▏                                          | 638976/1648877 [00:07<00:10, 92806.21it/s]\u001b[A\n",
      " 40%|███████████████████████████▊                                          | 655360/1648877 [00:08<00:12, 81444.09it/s]\u001b[A\n",
      " 41%|████████████████████████████▌                                         | 671744/1648877 [00:08<00:10, 95790.59it/s]\u001b[A\n",
      " 42%|█████████████████████████████▏                                        | 688128/1648877 [00:08<00:12, 78362.58it/s]\u001b[A\n",
      " 43%|██████████████████████████████▎                                       | 712704/1648877 [00:08<00:11, 81497.09it/s]\u001b[A\n",
      " 45%|███████████████████████████████▎                                      | 737280/1648877 [00:09<00:10, 82913.29it/s]\u001b[A\n",
      " 47%|████████████████████████████████▋                                     | 770048/1648877 [00:09<00:08, 97736.18it/s]\u001b[A\n",
      " 48%|█████████████████████████████████▍                                    | 786432/1648877 [00:09<00:10, 86170.14it/s]\u001b[A\n",
      " 50%|██████████████████████████████████▌                                  | 827392/1648877 [00:09<00:07, 104304.04it/s]\u001b[A\n",
      " 52%|███████████████████████████████████▋                                 | 851968/1648877 [00:09<00:06, 119345.03it/s]\u001b[A\n",
      " 53%|████████████████████████████████████▊                                 | 868352/1648877 [00:10<00:08, 93654.44it/s]\u001b[A\n",
      " 55%|█████████████████████████████████████▋                               | 901120/1648877 [00:10<00:06, 114458.26it/s]\u001b[A\n",
      " 56%|██████████████████████████████████████▋                              | 925696/1648877 [00:10<00:06, 117404.63it/s]\u001b[A\n",
      " 57%|███████████████████████████████████████▍                             | 942080/1648877 [00:10<00:06, 104990.72it/s]\u001b[A\n",
      " 58%|████████████████████████████████████████                             | 958464/1648877 [00:10<00:06, 111995.95it/s]\u001b[A\n",
      " 59%|████████████████████████████████████████▊                            | 974848/1648877 [00:10<00:05, 114083.17it/s]\u001b[A\n",
      " 61%|█████████████████████████████████████████▊                           | 999424/1648877 [00:11<00:06, 101969.20it/s]\u001b[A\n",
      " 62%|██████████████████████████████████████████▏                         | 1024000/1648877 [00:11<00:06, 100647.25it/s]\u001b[A\n",
      " 63%|███████████████████████████████████████████▌                         | 1040384/1648877 [00:11<00:07, 81415.18it/s]\u001b[A\n",
      " 65%|████████████████████████████████████████████▉                        | 1073152/1648877 [00:11<00:05, 98384.95it/s]\u001b[A\n",
      " 66%|████████████████████████████████████████████▉                       | 1089536/1648877 [00:11<00:05, 110957.25it/s]\u001b[A\n",
      " 67%|█████████████████████████████████████████████▌                      | 1105920/1648877 [00:12<00:05, 105293.04it/s]\u001b[A\n",
      " 68%|██████████████████████████████████████████████▎                     | 1122304/1648877 [00:12<00:04, 112967.05it/s]\u001b[A\n",
      " 69%|███████████████████████████████████████████████▋                     | 1138688/1648877 [00:12<00:05, 88528.53it/s]\u001b[A\n",
      " 70%|████████████████████████████████████████████████▎                    | 1155072/1648877 [00:12<00:06, 74449.97it/s]\u001b[A\n",
      " 71%|█████████████████████████████████████████████████                    | 1171456/1648877 [00:12<00:05, 86241.49it/s]\u001b[A\n",
      " 72%|█████████████████████████████████████████████████▋                   | 1187840/1648877 [00:13<00:05, 92120.92it/s]\u001b[A\n",
      " 73%|██████████████████████████████████████████████████▍                  | 1204224/1648877 [00:13<00:04, 98140.26it/s]\u001b[A\n",
      " 74%|██████████████████████████████████████████████████▎                 | 1220608/1648877 [00:13<00:03, 108251.15it/s]\u001b[A\n",
      " 75%|███████████████████████████████████████████████████                 | 1236992/1648877 [00:13<00:03, 118570.35it/s]\u001b[A\n",
      " 77%|████████████████████████████████████████████████████                | 1261568/1648877 [00:13<00:03, 125935.00it/s]\u001b[A\n",
      " 78%|█████████████████████████████████████████████████████               | 1286144/1648877 [00:13<00:02, 134808.80it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|█████████████████████████████████████████████████████▋              | 1302528/1648877 [00:13<00:02, 121861.86it/s]\u001b[A\n",
      " 80%|██████████████████████████████████████████████████████▋             | 1327104/1648877 [00:14<00:02, 140128.35it/s]\u001b[A\n",
      "9920512it [01:50, 113001.65it/s]                                                                                       \u001b[A\n",
      " 82%|████████████████████████████████████████████████████████▉            | 1359872/1648877 [00:14<00:03, 91620.65it/s]\u001b[A\n",
      " 83%|█████████████████████████████████████████████████████████▌           | 1376256/1648877 [00:14<00:03, 80560.03it/s]\u001b[A\n",
      " 84%|██████████████████████████████████████████████████████████▎          | 1392640/1648877 [00:14<00:02, 85716.45it/s]\u001b[A\n",
      " 85%|██████████████████████████████████████████████████████████▉          | 1409024/1648877 [00:15<00:03, 75940.32it/s]\u001b[A\n",
      " 86%|███████████████████████████████████████████████████████████▋         | 1425408/1648877 [00:15<00:02, 76234.06it/s]\u001b[A\n",
      " 87%|████████████████████████████████████████████████████████████▎        | 1441792/1648877 [00:15<00:02, 88180.24it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████████████████████████████        | 1458176/1648877 [00:15<00:02, 93382.91it/s]\u001b[A\n",
      " 89%|████████████████████████████████████████████████████████████▊       | 1474560/1648877 [00:15<00:01, 102989.05it/s]\u001b[A\n",
      " 90%|█████████████████████████████████████████████████████████████▍      | 1490944/1648877 [00:15<00:01, 115091.84it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████████████████████████████      | 1507328/1648877 [00:16<00:01, 98420.12it/s]\u001b[A\n",
      " 93%|███████████████████████████████████████████████████████████████▏    | 1531904/1648877 [00:16<00:00, 117656.82it/s]\u001b[A\n",
      " 94%|███████████████████████████████████████████████████████████████▊    | 1548288/1648877 [00:16<00:00, 104254.33it/s]\u001b[A\n",
      " 95%|████████████████████████████████████████████████████████████████▌   | 1564672/1648877 [00:16<00:00, 111853.02it/s]\u001b[A\n",
      " 96%|█████████████████████████████████████████████████████████████████▏  | 1581056/1648877 [00:16<00:00, 119937.69it/s]\u001b[A\n",
      " 97%|██████████████████████████████████████████████████████████████████▊  | 1597440/1648877 [00:16<00:00, 99530.04it/s]\u001b[A\n",
      " 98%|██████████████████████████████████████████████████████████████████▌ | 1613824/1648877 [00:17<00:00, 110375.25it/s]\u001b[A\n",
      " 99%|███████████████████████████████████████████████████████████████████▏| 1630208/1648877 [00:17<00:00, 105403.76it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████████████████████████████▉| 1646592/1648877 [00:17<00:00, 115981.02it/s]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist_train\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to mnist_train\\MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to mnist_train\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "8192it [00:00, 26481.66it/s]                                                                                           \u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist_train\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to mnist_train\\MNIST\\raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1654784it [00:34, 115981.02it/s]                                                                                       \u001b[A"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Writer will output to ./runs/ directory by default\n",
    "writer = SummaryWriter()\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "trainset = datasets.MNIST('mnist_train', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "model = torchvision.models.resnet50(False)\n",
    "# Have ResNet model take in grayscale rather than RGB\n",
    "model.conv1 = torch.nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "grid = torchvision.utils.make_grid(images)\n",
    "writer.add_image('images', grid, 0)\n",
    "writer.add_graph(model, images)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "\n",
    "writer = SummaryWriter()\n",
    "\n",
    "for n_iter in range(100):\n",
    "    writer.add_scalar('Loss/train', np.random.random(), n_iter)\n",
    "    writer.add_scalar('Loss/test', np.random.random(), n_iter)\n",
    "    writer.add_scalar('Accuracy/train', np.random.random(), n_iter)\n",
    "    writer.add_scalar('Accuracy/test', np.random.random(), n_iter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 4e-2\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=32, dmax_len=10000, docs='../ruwikIR/processed_documents.csv', drop_prob=0.6, embeddings='/home/mrim/data/embeddings/cc.ru.300.bin', epoches=2, inverted_index='./inverted_index.csv', layers=[300, 200, 5000], learning_rate=5e-05, output_file='./model.pth', params='params_local.json', qmax_len=100, qrels='../ruwikIR/qrels', queries='../ruwikIR/processed_queries.csv', reg_lambda=1e-07)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 85, in <module>\n",
      "    run(args)\n",
      "  File \"train.py\", line 64, in run\n",
      "    dmax_len=args.dmax_len,\n",
      "  File \"C:\\Users\\sonya\\Desktop\\snrm-bert\\snrm\\snrm.py\", line 48, in __init__\n",
      "    self.embeddings = Embeddings(fembeddings)\n",
      "  File \"C:\\Users\\sonya\\Desktop\\snrm-bert\\snrm\\snrm.py\", line 14, in __init__\n",
      "    self.model = fasttext.load_model(emb_file)\n",
      "  File \"C:\\Users\\sonya\\Anaconda3\\lib\\site-packages\\fasttext\\FastText.py\", line 350, in load_model\n",
      "    return _FastText(model_path=path)\n",
      "  File \"C:\\Users\\sonya\\Anaconda3\\lib\\site-packages\\fasttext\\FastText.py\", line 43, in __init__\n",
      "    self.f.loadModel(model_path)\n",
      "ValueError: /home/mrim/data/embeddings/cc.ru.300.bin cannot be opened for loading!\n"
     ]
    }
   ],
   "source": [
    "!python train.py --params=params_local.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"ls\" ­Ґ пў«пҐвбп ў­гваҐ­­Ґ© Ё«Ё ў­Ґи­Ґ©\n",
      "Є®¬ ­¤®©, ЁбЇ®«­пҐ¬®© Їа®Ја ¬¬®© Ё«Ё Ї ЄҐв­л¬ д ©«®¬.\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
